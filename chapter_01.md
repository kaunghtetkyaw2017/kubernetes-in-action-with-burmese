# အခန်း (၁) Kubernetes ကို မိတ်ဆက်ခြင်း

**ဤအခန်းတွင် ပါဝင်သောအကြောင်းအရာများ**

* Kubernetes နှင့် ၎င်း၏မူလအစအကြောင်း အကြိုမိတ်ဆက်
* Kubernetes ကို အဘယ်ကြောင့် တွင်တွင်ကျယ်ကျယ် အသုံးပြုလာကြသနည်း
* Kubernetes က သင်၏ data center ကို မည်သို့ပြောင်းလဲပေးနိုင်သနည်း
* ၎င်း၏ architecture နှင့် လုပ်ဆောင်ပုံ အကျဉ်းချုပ်
* သင်၏အဖွဲ့အစည်းတွင် Kubernetes ကို မည်သို့ ပေါင်းစပ်အသုံးပြုသင့်သနည်း၊ အသုံးပြုသင့် မသင့်

Kubernetes ဖြင့် application များ run ခြင်း၏ အသေးစိတ်အချက်အလက်များကို မလေ့လာမီ၊ Kubernetes က ဖြေရှင်းရန် ရည်ရွယ်ထားသော ပြဿနာများ၊ ၎င်းမည်သို့ပေါ်ပေါက်လာပုံ နှင့် application development နှင့် deployment အပေါ် ၎င်း၏အကျိုးသက်ရောက်မှုများကို အခြေခံနားလည်ထားရန် လိုအပ်ပါသည်။ ဤပထမအခန်းသည် ထိုအကြောင်းအရာများကို ခြုံငုံသုံးသပ်ပေးရန် ရည်ရွယ်ပါသည်။

## 1.1 Kubernetes ကို မိတ်ဆက်ခြင်း

Kubernetes ဆိုသော စကားလုံးသည် သင်္ဘောကို ထိန်းကျောင်းမောင်းနှင်သူ သို့မဟုတ် တက်မကိုင် (helmsman) ဟု အဓိပ္ပာယ်ရသော ဂရိစကားလုံးဖြစ်ပါသည်။ တက်မကိုင်ဆိုသည်မှာ သင်္ဘောကပ္ပတိန်နှင့် အတူတူဟု ဆိုလိုခြင်းမဟုတ်ပါ။ ကပ္ပတိန်သည် သင်္ဘောတစ်စီးလုံးအတွက် တာဝန်ရှိသူဖြစ်ပြီး၊ တက်မကိုင်သည် သင်္ဘောကို ထိန်းကျောင်းသူသာ ဖြစ်ပါသည်။

Kubernetes ၏ လုပ်ဆောင်ချက်များကို ပိုမိုလေ့လာပြီးနောက်၊ ဤအမည်သည် အလွန်လိုက်ဖက်ကြောင်း သင်တွေ့ရှိလာပါလိမ့်မည်။ တက်မကိုင်သည် သင်္ဘော၏ ခရီးလမ်းကြောင်းကို ထိန်းသိမ်းပေးခြင်း၊ ကပ္ပတိန်၏ အမိန့်များကို လိုက်နာဆောင်ရွက်ခြင်းနှင့် သင်္ဘော၏ ဦးတည်ရာကို ပြန်လည်အစီရင်ခံခြင်းများ ပြုလုပ်ပါသည်။ Kubernetes သည် သင်၏ application များကို ထိန်းကျောင်းပေးပြီး ၎င်းတို့၏ အခြေအနေကို အစီရင်ခံနေချိန်တွင် သင် (ကပ္ပတိန်) က system ကို မည်သည့်နေရာသို့ သွားစေလိုသည်ကို ဆုံးဖြတ်ပေးရုံသာ ဖြစ်ပါသည်။

**Kubernetes ကို ဘယ်လိုအသံထွက်မလဲ၊ k8s ဆိုတာဘာလဲ။**

Kubernetes ၏ မှန်ကန်သော ဂရိအသံထွက်မှာ 'ကီ-ဗာ-နီး-တီးစ်' (Kie-ver-nee-tees) ဖြစ်ပြီး၊ နည်းပညာစကားပြောများတွင် ကြားနေကျ အင်္ဂလိပ်အသံထွက်နှင့် ကွဲပြားပါသည်။ အများစုမှာ 'ကူ-ဘာ-နက်-တီးစ်' (Koo-ber-netties) သို့မဟုတ် 'ကူ-ဘာ-နေး-တေ့စ်' (Koo-ber-nay'-tace) ဟု အသံထွက်ကြသော်လည်း၊ 'ကူ-ဘာ-နက်စ်' (Koo-ber-nets) ဟု အသံထွက်သည်ကို ရှားရှားပါးပါး ကြားရနိုင်ပါသည်။

စာဖြင့်ရေးသားရာတွင်ဖြစ်စေ၊ စကားပြောရာတွင်ဖြစ်စေ ၎င်းကို 'Kube' (ကျူ့ဘ်) သို့မဟုတ် 'K8s' (ကိတ်စ်) ဟုလည်း ရည်ညွှန်းကြသည်။ 'K8s' ရှိ ဂဏန်း 8 သည် ပထမဆုံးစာလုံးနှင့် နောက်ဆုံးစာလုံးကြားတွင် ချန်လှပ်ထားသော စာလုံးအရေအတွက်ကို ကိုယ်စားပြုပါသည်။

### 1.1.1 Kubernetes အနှစ်ချုပ်

Kubernetes ဆိုသည်မှာ container များအတွင်းတွင် run နေသော ကွန်ပျူတာ process များဖြင့် ဖွဲ့စည်းထားသည့် ရှုပ်ထွေးပြီး ကြီးမားသော application system များကို deploy လုပ်ခြင်းနှင့် စီမံခန့်ခွဲခြင်းတို့ကို အလိုအလျောက် လုပ်ဆောင်ပေးသော software system တစ်ခုဖြစ်သည်။ ၎င်းက ဘာတွေလုပ်ဆောင်ပေးသလဲ၊ ဘယ်လိုလုပ်ဆောင်ပေးသလဲဆိုတာကို လေ့လာကြည့်ကြပါစို့။

**Infrastructure ကို ကွယ်ဝှက်၍ abstraction ပြုလုပ်ခြင်း**

Software developer များ သို့မဟုတ် operator များက application တစ်ခုကို deploy လုပ်ရန် ဆုံးဖြတ်သည့်အခါ၊ application ကို ကွန်ပျူတာတစ်လုံးချင်းစီသို့ တိုက်ရိုက် deploy မလုပ်ဘဲ Kubernetes မှတစ်ဆင့် deploy လုပ်ကြပါသည်။ Kubernetes သည် အသုံးပြုသူများနှင့် application များအတွက် အောက်ခံ hardware အပေါ်တွင် abstraction layer (အပေါ်ယံလွှာ) တစ်ခုကို ဖြည့်ဆည်းပေးပါသည်။

အောက်ပါပုံတွင် မြင်တွေ့ရသည့်အတိုင်း၊ အောက်ခံ infrastructure ဖြစ်သော ကွန်ပျူတာများ၊ network နှင့် အခြားသော အစိတ်အပိုင်းများကို application များထံမှ ဖုံးကွယ်ထားသောကြောင့် application များကို develop လုပ်ရန်နှင့် configure လုပ်ရန် ပိုမိုလွယ်ကူစေပါသည်။

**ပုံ 1.1 Kubernetes ကို အသုံးပြု၍ Infrastructure abstraction ပြုလုပ်ခြင်း**

**Application များကို deploy လုပ်သည့်ပုံစံကို စံသတ်မှတ်ခြင်း**

အောက်ခံ infrastructure ၏ အသေးစိတ်အချက်အလက်များသည် application များ၏ deployment အပေါ် သက်ရောက်မှုမရှိတော့သောကြောင့်၊ သင်သည် corporate data center တွင် application များကို deploy လုပ်သည့်ပုံစံအတိုင်း cloud တွင်လည်း deploy လုပ်နိုင်ပါသည်။ application ကို ဖော်ပြသည့် manifest တစ်ခုတည်းကို local deployment အတွက်ရော၊ မည်သည့် cloud provider တွင်မဆို deploy လုပ်ရန်အတွက်ပါ အသုံးပြုနိုင်ပါသည်။ အောက်ခံ infrastructure များ၏ ကွာခြားချက်အားလုံးကို Kubernetes က ကိုင်တွယ်ဖြေရှင်းပေးသောကြောင့် သင်သည် application နှင့် ၎င်းတွင်ပါဝင်သော business logic ကိုသာ အာရုံစိုက်နိုင်ပါသည်။

**Application များကို declarative model ဖြင့် deploy လုပ်ခြင်း**

Kubernetes သည် application တစ်ခုကို သတ်မှတ်ဖော်ပြရန်အတွက် declarative model (ကြေညာချက်ပုံစံ) ကို အသုံးပြုပါသည်။ သင်သည် သင်၏ application ကို ဖွဲ့စည်းထားသော အစိတ်အပိုင်းများ (components) ကို ဖော်ပြပေးပြီး Kubernetes က ထိုဖော်ပြချက်ကို run နေသော application တစ်ခုအဖြစ်သို့ ပြောင်းလဲပေးပါသည်။ ထို့နောက် လိုအပ်သလို အစိတ်အပိုင်းများကို restart လုပ်ခြင်း သို့မဟုတ် အသစ်ပြန်လည်ဖန်တီးခြင်းဖြင့် application ကို ကောင်းမွန်စွာ အလုပ်လုပ်နေစေရန် ထိန်းသိမ်းပေးပါသည်။

**ပုံ 1.2 Application deployment ၏ declarative model**

သင်သည် ဖော်ပြချက်ကို ပြောင်းလဲလိုက်သည့်အခါတိုင်း၊ Kubernetes သည် run နေသော application ကို ဖော်ပြချက်အသစ်နှင့် ကိုက်ညီအောင် ပြန်လည် configure လုပ်ရန် လိုအပ်သော အဆင့်များကို လုပ်ဆောင်ပေးပါမည်။

**ပုံ 1.3 ဖော်ပြချက်ပြောင်းလဲမှုများသည် run နေသော application တွင် ထင်ဟပ်လာပုံ**

**Application များ၏ နေ့စဉ်စီမံခန့်ခွဲမှုကို တာဝန်ယူခြင်း**

Application တစ်ခုကို Kubernetes သို့ deploy လုပ်ပြီးသည်နှင့်တစ်ပြိုင်နက်၊ ၎င်းသည် application ၏ နေ့စဉ်စီမံခန့်ခွဲမှုကို လွှဲပြောင်းယူလိုက်ပါသည်။ အကယ်၍ application fail ဖြစ်သွားပါက Kubernetes က ၎င်းကို အလိုအလျောက် restart လုပ်ပေးပါမည်။ Hardware fail ဖြစ်သွားခြင်း သို့မဟုတ် infrastructure topology ပြောင်းလဲသွားခြင်းကြောင့် application ကို အခြားစက်များသို့ ရွှေ့ပြောင်းရန် လိုအပ်လာပါက၊ Kubernetes က ဤအရာအားလုံးကို သူ့အလိုလို လုပ်ဆောင်ပေးပါသည်။ System ကို operate လုပ်ရန် တာဝန်ရှိသော engineer များသည် အသေးစိတ်အချက်များတွင် အချိန်ဖြုန်းမည့်အစား အလုံးစုံခြုံငုံသုံးသပ်မှု (big picture) ကိုသာ အာရုံစိုက်နိုင်ပါသည်။

သင်္ဘော analogy သို့ ပြန်သွားရလျှင်၊ development နှင့် operations engineer များသည် အဆင့်မြင့်ဆုံးဖြတ်ချက်များ ချမှတ်ပေးသော သင်္ဘောအရာရှိများဖြစ်ပြီး Kubernetes သည် သင်၏ application များနှင့် infrastructure တို့ ဖြတ်သန်းရသော ကြမ်းတမ်းသည့် ရေပြင်တွင် system ကို ထိန်းကျောင်းပေးသည့် တက်မကိုင်ဖြစ်ပါသည်။

**ပုံ 1.4 Kubernetes သည် application များ၏ စီမံခန့်ခွဲမှုကို လွှဲပြောင်းယူခြင်း**

Kubernetes ၏ လုပ်ဆောင်ချက်များနှင့် ၎င်းဆောင်ကျဉ်းပေးသော အားသာချက်များအားလုံးကို ပိုမိုရှည်လျားသော ရှင်းလင်းချက် လိုအပ်ပါသည်။ ထိုအကြောင်းကို နောက်ပိုင်းတွင် ဆွေးနွေးပါမည်။ ထိုသို့မလုပ်မီ၊ ၎င်းမည်သို့ စတင်ခဲ့သည်နှင့် Kubernetes project ၏ လက်ရှိအခြေအနေကို သိရှိထားခြင်းက သင့်အတွက် အထောက်အကူဖြစ်နိုင်ပါသည်။

### 1.1.2 Kubernetes project အကြောင်း

Kubernetes ကို Google မှ မူလက develop လုပ်ခဲ့ပါသည်။ Google သည် application များကို container များထဲတွင် အမြဲတမ်းနီးပါး run ခဲ့သည်။ ၂၀၁၄ ခုနှစ်ကတည်းက၊ ၎င်းတို့သည် တစ်ပတ်လျှင် container နှစ်ဘီလီယံ စတင် run ကြောင်း သတင်းထုတ်ပြန်ခဲ့သည်။ ထိုပမာဏသည် တစ်စက္ကန့်လျှင် container ၃,၀၀၀ ကျော်ဖြစ်ပြီး ယနေ့ခေတ်တွင် ထိုပမာဏသည် ပိုမိုများပြားနေပြီဖြစ်သည်။ ၎င်းတို့သည် ထို container များကို ကမ္ဘာတစ်ဝှမ်းရှိ data center ဒါဇင်ပေါင်းများစွာတွင် ဖြန့်ကျက်ထားသော ကွန်ပျူတာ ထောင်ပေါင်းများစွာပေါ်တွင် run နေပါသည်။ ဤအရာအားလုံးကို လူကိုယ်တိုင် လုပ်ဆောင်နေရသည်ကို မြင်ယောင်ကြည့်ပါ။ Automation လိုအပ်သည်မှာ ရှင်းလင်းပြီး ဤမျှကြီးမားသော scale တွင် ၎င်းသည် ပြီးပြည့်စုံရန် လိုအပ်ပါသည်။

**Borg နှင့် Omega - Kubernetes ၏ ရှေ့ပြေးများအကြောင်း**

Google ၏ workload ကြီးမားမှုသည် software component ထောင်ပေါင်းများစွာ၏ development နှင့် management ကို စီမံခန့်ခွဲနိုင်ပြီး ကုန်ကျစရိတ်သက်သာစေရန် ဖြေရှင်းနည်းများ develop လုပ်ရန် ၎င်းတို့ကို တွန်းအားပေးခဲ့သည်။ နှစ်များတစ်လျှောက်၊ Google သည် Borg (နောက်ပိုင်းတွင် Omega ဟုခေါ်သော system အသစ်) ဟုခေါ်သော internal system တစ်ခုကို develop လုပ်ခဲ့ပြီး၊ ၎င်းသည် application developer များနှင့် operator များအား ထို application နှင့် service ထောင်ပေါင်းများစွာကို စီမံခန့်ခွဲရာတွင် အထောက်အကူပြုခဲ့သည်။

Development နှင့် management ကို ရိုးရှင်းစေသည့်အပြင်၊ ဤ system များသည် ၎င်းတို့၏ infrastructure ကို ပိုမိုကောင်းမွန်စွာ အသုံးပြုနိုင်စေရန်လည်း ကူညီပေးခဲ့သည်။ ၎င်းသည် မည်သည့်အဖွဲ့အစည်းတွင်မဆို အရေးကြီးသော်လည်း၊ သင်သည် စက်သိန်းပေါင်းများစွာကို operate လုပ်နေသည့်အခါ၊ အသုံးပြုမှုတွင် အနည်းငယ်တိုးတက်မှုလေးများကပင် သန်းပေါင်းများစွာသော ချွေတာမှုကို ဆိုလိုသောကြောင့်၊ ထိုကဲ့သို့သော system တစ်ခုကို develop လုပ်ရန်အတွက် တွန်းအားများမှာ ရှင်းလင်းပါသည်။

> **မှတ်ချက်**
> Google ၏ စွမ်းအင်အသုံးပြုမှုဆိုင်ရာ အချက်အလက်များအရ ၎င်းတို့သည် server ပေါင်း ၉၀၀,၀၀၀ ခန့် run နေကြောင်း ညွှန်ပြနေသည်။

အချိန်ကြာလာသည်နှင့်အမျှ၊ သင်၏ infrastructure သည် ကြီးထွားလာပြီး ပြောင်းလဲတိုးတက်လာပါသည်။ data center အသစ်တိုင်းသည် state-of-the-art ဖြစ်သည်။ ၎င်း၏ infrastructure သည် ယခင်က တည်ဆောက်ခဲ့သော infrastructure များနှင့် ကွဲပြားပါသည်။ ကွဲပြားမှုများရှိနေသော်လည်း၊ data center တစ်ခုတွင် application များကို deploy လုပ်ခြင်းသည် အခြား data center တစ်ခုတွင် deploy လုပ်ခြင်းနှင့် မကွာခြားသင့်ပါ။ ဒေသဆိုင်ရာ ချို့ယွင်းမှုကြောင့် application downtime ဖြစ်နိုင်ခြေကို လျှော့ချရန်အတွက် သင်၏ application ကို နေရာဒေသ (zone) သို့မဟုတ် တိုင်းဒေသ (region) များစွာတွင် deploy လုပ်သည့်အခါ ၎င်းသည် အထူးအရေးကြီးပါသည်။ ထိုသို့ထိရောက်စွာ လုပ်ဆောင်နိုင်ရန်၊ သင်၏ application များကို deploy လုပ်ရန်အတွက် တသမတ်တည်းဖြစ်သော နည်းလမ်းတစ်ခုရှိရန်မှာ အရေးကြီးပါသည်။

**Kubernetes - open-source project - နှင့် ၎င်းမှဆင်းသက်လာသော commercial product များအကြောင်း**

Borg, Omega နှင့် အခြားသော internal system များကို develop လုပ်ခဲ့စဉ်က ရရှိခဲ့သော အတွေ့အကြုံများအပေါ် အခြေခံ၍ Google သည် ၂၀၁၄ ခုနှစ်တွင် Kubernetes ကို မိတ်ဆက်ခဲ့သည်။ ၎င်းသည် open-source project တစ်ခုဖြစ်ပြီး ယခုအခါ လူတိုင်းက အသုံးပြုနိုင်ပြီး ထပ်မံတိုးတက်အောင် လုပ်ဆောင်နိုင်ပြီ ဖြစ်သည်။

**ပုံ 1.5 Kubernetes open-source project ၏ မူလအစနှင့် အခြေအနေ**

Kubernetes ကို ကြေညာပြီး မကြာမီမှာပင်၊ version 1.0 တရားဝင်မထွက်မီကတည်းက၊ open-source software ၏ ရှေ့တန်းမှ အမြဲရှိနေခဲ့သော Red Hat ကဲ့သို့သော အခြားကုမ္ပဏီများသည် လျင်မြန်စွာ ပါဝင်လာပြီး project ကို develop လုပ်ရာတွင် ကူညီခဲ့ကြသည်။ ၎င်းသည် နောက်ဆုံးတွင် ၎င်း၏တည်ထောင်သူများ၏ မျှော်လင့်ချက်များထက် များစွာ ကျော်လွန်ကြီးထွားလာခဲ့ပြီး၊ ယနေ့တွင် အဖွဲ့အစည်း ဒါဇင်ပေါင်းများစွာနှင့် လူပုဂ္ဂိုလ် ထောင်ပေါင်းများစွာက ပါဝင်ကူညီနေကြသော ကမ္ဘာ့ထိပ်တန်း open-source project များထဲမှ တစ်ခုဖြစ်သည်မှာ သေချာပါသည်။

ကုမ္ပဏီများစွာသည် ယခုအခါ open-source project မှ တည်ဆောက်ထားသော enterprise-quality Kubernetes product များကို ကမ်းလှမ်းလျက်ရှိသည်။ ၎င်းတို့တွင် Red Hat OpenShift, Pivotal Container Service, Rancher နှင့် အခြားများစွာ ပါဝင်ပါသည်။

**Kubernetes က cloud-native eco-system အသစ်တစ်ခုလုံးကို မည်သို့ ကြီးထွားစေခဲ့သနည်း**

Kubernetes သည် အခြားသော ဆက်စပ် open-source project များစွာကိုလည်း ပေါ်ပေါက်စေခဲ့ပြီး၊ ၎င်းတို့အများစုမှာ ယခုအခါ Cloud Native Computing Foundation (CNCF) ၏ အောက်တွင် ရှိနေပါသည်။ CNCF သည် Linux Foundation ၏ အစိတ်အပိုင်းတစ်ခု ဖြစ်ပါသည်။

CNCF သည် မြောက်အမေရိက၊ ဥရောပနှင့် တရုတ်နိုင်ငံတို့တွင် တစ်နှစ်လျှင် KubeCon - CloudNativeCon conference များစွာကို ကျင်းပပေးပါသည်။ ၂၀၁၉ ခုနှစ်တွင် စုစုပေါင်းတက်ရောက်သူ အရေအတွက်သည် ၂၃,၀၀၀ ကျော်လွန်ခဲ့ပြီး၊ KubeCon North America သည် တက်ရောက်သူ ၁၂,၀၀၀ ဖြင့် အလွန်များပြားသော အရေအတွက်သို့ ရောက်ရှိခဲ့သည်။ ဤကိန်းဂဏန်းများက Kubernetes သည် ယနေ့ ကမ္ဘာတစ်ဝှမ်းရှိ ကုမ္ပဏီများ application deploy လုပ်သည့်ပုံစံအပေါ် အလွန်အမင်း အပြုသဘောဆောင်သော အကျိုးသက်ရောက်မှု ရှိခဲ့ကြောင်း ပြသနေပါသည်။ ထိုသို့မဟုတ်ပါက ၎င်းကို ဤမျှ တွင်ကျယ်စွာ လက်ခံကျင့်သုံးကြမည် မဟုတ်ပါ။

### 1.1.3 Kubernetes အဘယ်ကြောင့် ဤမျှ လူကြိုက်များရသည်ကို နားလည်ခြင်း

မကြာသေးမီနှစ်များအတွင်း၊ ကျွန်ုပ်တို့ application develop လုပ်သည့်ပုံစံသည် သိသိသာသာ ပြောင်းလဲလာခဲ့သည်။ ၎င်းသည် Kubernetes ကဲ့သို့သော tool အသစ်များ develop လုပ်ရန် ဦးတည်စေခဲ့ပြီး၊ ၎င်းကပင် application architecture နှင့် ကျွန်ုပ်တို့ develop လုပ်သည့်ပုံစံတွင် နောက်ထပ်ပြောင်းလဲမှုများကို ပြန်လည်တွန်းအားပေးခဲ့သည်။ ဤအကြောင်းအတွက် ခိုင်မာသော ဥပမာများကို ကြည့်ကြပါစို့။

**Microservice များ၏ စီမံခန့်ခွဲမှုကို အလိုအလျောက်လုပ်ဆောင်ခြင်း**

ယခင်က application အများစုသည် ကြီးမားသော monolith များဖြစ်ကြသည်။ Application ၏ component များသည် တင်းကျပ်စွာ ချိတ်ဆက်ထားပြီး၊ ၎င်းတို့အားလုံးသည် computer process တစ်ခုတည်းတွင် run ကြသည်။ Application ကို developer အဖွဲ့ကြီးတစ်ခုက တစ်ခုတည်းသော unit အဖြစ် develop လုပ်ပြီး application ၏ deployment သည် ရိုးရှင်းပါသည်။ သင်သည် ၎င်းကို အစွမ်းထက်သော ကွန်ပျူတာတစ်လုံးပေါ်တွင် install လုပ်ပြီး လိုအပ်သော configuration အနည်းငယ်ကို ပေးရုံသာဖြစ်သည်။ Application ကို horizontally scale လုပ်ခြင်းသည် ရှားရှားပါးပါးသာ ဖြစ်နိုင်သောကြောင့်၊ application ၏ capacity ကို တိုးမြှင့်ရန် လိုအပ်သည့်အခါတိုင်း၊ သင်သည် hardware ကို upgrade လုပ်ရသည် - တစ်နည်းအားဖြင့် application ကို vertically scale လုပ်ရသည်။

ထို့နောက် microservices paradigm ပေါ်ပေါက်လာခဲ့သည်။ Monolith များကို သီးခြား process ဒါဇင်ပေါင်းများစွာ၊ တစ်ခါတစ်ရံ ရာပေါင်းများစွာအထိ ခွဲခြမ်းခဲ့သည်။ ၎င်းသည် အဖွဲ့အစည်းများအား ၎င်းတို့၏ development department များကို အဖွဲ့ငယ်များအဖြစ် ခွဲဝေနိုင်စေပြီး၊ အဖွဲ့တစ်ခုစီသည် system တစ်ခုလုံး၏ အစိတ်အပိုင်းတစ်ခု - microservice အချို့ကိုသာ develop လုပ်ကြပါသည်။

**ပုံ 1.6 Monolithic application များနှင့် microservice များကို နှိုင်းယှဉ်ခြင်း**

Microservice တစ်ခုစီသည် ယခုအခါ ၎င်း၏ကိုယ်ပိုင် development နှင့် release cycle ရှိသော သီးခြား application တစ်ခုဖြစ်သည်။ မတူညီသော microservice များ၏ dependency များသည် အချိန်ကြာလာသည်နှင့်အမျှ မလွဲမသွေ ကွဲပြားသွားပါမည်။ Microservice တစ်ခုသည် library ၏ version တစ်ခုကို လိုအပ်ပြီး၊ အခြား microservice တစ်ခုသည် ထို library ၏ အခြားသော၊ တစ်ခါတစ်ရံ တွဲဖက်မသုံးနိုင်သော၊ version တစ်ခုကို လိုအပ်ပေမည်။ Application နှစ်ခုကို တူညီသော operating system တွင် run ရန် ခက်ခဲလာပါသည်။

ကံကောင်းစွာဖြင့်၊ container များချည်းကပင် microservice တစ်ခုစီသည် မတူညီသော environment လိုအပ်သည့် ဤပြဿနာကို ဖြေရှင်းပေးနိုင်သော်လည်း၊ microservice တစ်ခုစီသည် ယခုအခါ တစ်ခုချင်းစီ စီမံခန့်ခွဲရမည့် သီးခြား application တစ်ခု ဖြစ်လာပါသည်။ Application အရေအတွက် တိုးများလာခြင်းက ဤအရာကို ပိုမိုခက်ခဲစေပါသည်။

Application တစ်ခုလုံး၏ သီးခြားအစိတ်အပိုင်းများသည် တူညီသော ကွန်ပျူတာပေါ်တွင် run ရန် မလိုအပ်တော့သောကြောင့် system တစ်ခုလုံးကို scale လုပ်ရန် ပိုမိုလွယ်ကူစေသော်လည်း၊ application များကို တစ်ခုနှင့်တစ်ခု ဆက်သွယ်နိုင်ရန် configure လုပ်ရန် လိုအပ်သည်ဟု ဆိုလိုပါသည်။ Component အနည်းငယ်သာရှိသော system များအတွက်၊ ၎င်းကို များသောအားဖြင့် လူကိုယ်တိုင် လုပ်ဆောင်နိုင်သော်လည်း၊ ယခုအခါ microservice ရာကျော်ပါဝင်သော deployment များကို တွေ့မြင်နေရသည်မှာ ပုံမှန်ဖြစ်လာပါသည်။

System သည် microservice များစွာဖြင့် ဖွဲ့စည်းထားသည့်အခါ၊ အလိုအလျောက် စီမံခန့်ခွဲမှုသည် အလွန်အရေးကြီးပါသည်။ Kubernetes သည် ဤ automation ကို ပံ့ပိုးပေးပါသည်။ ၎င်းကမ်းလှမ်းသော feature များသည် microservice ရာပေါင်းများစွာကို စီမံခန့်ခွဲသည့် တာဝန်ကို အလွန်လွယ်ကူစေပါသည်။

**Dev နှင့် Ops ကြားက ကွာဟချက်ကို ပေါင်းကူးပေးခြင်း**

Application architecture တွင် ဤပြောင်းလဲမှုများနှင့်အတူ၊ အဖွဲ့များ software develop လုပ်ပြီး run သည့်ပုံစံတွင်လည်း ပြောင်းလဲမှုများကို တွေ့မြင်ခဲ့ရသည်။ ယခင်က development အဖွဲ့သည် software ကို သီးခြား တည်ဆောက်ပြီးနောက် ပြီးစီးသွားသော product ကို operations အဖွဲ့ထံသို့ ပစ်ပေးလိုက်သည်မှာ ပုံမှန်ဖြစ်ခဲ့ပြီး၊ ထိုအဖွဲ့က ၎င်းကို deploy လုပ်ပြီး စီမံခန့်ခွဲပါသည်။

DevOps paradigm ပေါ်ပေါက်လာသည်နှင့်အမျှ၊ အဖွဲ့နှစ်ဖွဲ့သည် ယခုအခါ software product ၏ သက်တမ်းတစ်လျှောက်လုံးတွင် ပိုမိုနီးကပ်စွာ အတူတကွ လုပ်ဆောင်ကြပါသည်။ Development အဖွဲ့သည် ယခုအခါ deploy လုပ်ထားသော software ၏ နေ့စဉ်စီမံခန့်ခွဲမှုတွင် ပိုမိုပါဝင်လာပါသည်။ သို့သော် ၎င်းက ၎င်းတို့သည် ၎င်း run နေသော infrastructure အကြောင်းကို ယခုအခါ သိရှိရန် လိုအပ်သည်ဟု ဆိုလိုပါသည်။

Software developer တစ်ယောက်အနေဖြင့်၊ သင်၏ အဓိကအာရုံစိုက်မှုမှာ business logic ကို implement လုပ်ရန်ဖြစ်သည်။ သင်သည် အောက်ခံ server များ၏ အသေးစိတ်အချက်အလက်များနှင့် ပတ်သက်၍ ကိုင်တွယ်လိုမည်မဟုတ်ပါ။ ကံကောင်းစွာဖြင့်၊ Kubernetes သည် ဤအသေးစိတ်အချက်အလက်များကို ဖုံးကွယ်ပေးပါသည်။

**Cloud ကို စံသတ်မှတ်ခြင်း**

လွန်ခဲ့သော ဆယ်စုနှစ် သို့မဟုတ် နှစ်ခုအတွင်း၊ အဖွဲ့အစည်းများစွာသည် ၎င်းတို့၏ software များကို local server များမှ cloud သို့ ရွှေ့ပြောင်းခဲ့ကြသည်။ ဤသို့ပြုလုပ်ခြင်း၏ အကျိုးကျေးဇူးများသည် သီးခြား cloud provider တစ်ခုသို့ မှီခိုသွားရမည်ကို စိုးရိမ်မှုထက် သာလွန်ပုံရသည်။ ထိုစိုးရိမ်မှုမှာ application များကို deploy လုပ်ပြီး စီမံခန့်ခွဲရန် provider ၏ ကိုယ်ပိုင် API များကို အားကိုးခြင်းကြောင့် ဖြစ်ပေါ်လာပါသည်။

၎င်းတို့၏ application များကို provider တစ်ခုမှ အခြားတစ်ခုသို့ ရွှေ့ပြောင်းနိုင်လိုသော မည်သည့်ကုမ္ပဏီမဆို၊ application များမှ အောက်ခံ cloud provider ၏ infrastructure နှင့် API များကို abstract လုပ်ရန် အစပိုင်းတွင် မလိုအပ်သော အပိုများ ပြုလုပ်ရပါမည်။ ၎င်းသည် အဓိက business logic တည်ဆောက်မှုအပေါ် အာရုံစိုက်နိုင်မည့် အရင်းအမြစ်များကို လိုအပ်စေပါသည်။

Kubernetes သည် ဤကိစ္စတွင်လည်း အထောက်အကူပြုခဲ့သည်။ Kubernetes ၏ လူကြိုက်များမှုသည် အဓိက cloud provider အားလုံးကို ၎င်းတို့၏ ဝန်ဆောင်မှုများတွင် Kubernetes ကို ပေါင်းစပ်ထည့်သွင်းရန် တွန်းအားပေးခဲ့သည်။ Customer များသည် ယခုအခါ Kubernetes မှ ပံ့ပိုးပေးသော စံ API အစုံဖြင့် မည်သည့် cloud provider တွင်မဆို application များကို deploy လုပ်နိုင်ပြီ ဖြစ်သည်။

**ပုံ 1.7 Kubernetes သည် cloud provider များပေါ်တွင် application deploy လုပ်သည့်ပုံစံကို စံသတ်မှတ်ပေးခဲ့သည်**

အကယ်၍ application ကို သီးခြား cloud provider တစ်ခု၏ ကိုယ်ပိုင် API များပေါ်တွင် တိုက်ရိုက် တည်ဆောက်မည့်အစား Kubernetes ၏ API များပေါ်တွင် တည်ဆောက်ပါက၊ ၎င်းကို အခြား မည်သည့် provider သို့မဆို အတော်လေး လွယ်ကူစွာ ရွှေ့ပြောင်းနိုင်ပါသည်။

## 1.2 Kubernetes ကို နားလည်ခြင်း

ယခင်အပိုင်းသည် Kubernetes ၏ မူလအစနှင့် ၎င်းကို တွင်ကျယ်စွာ အသုံးပြုရခြင်း၏ အကြောင်းရင်းများကို ရှင်းပြခဲ့သည်။ ဤအပိုင်းတွင် Kubernetes သည် အတိအကျ ဘာလဲဆိုတာကို ပိုမိုအသေးစိတ် ကြည့်ရှုပါမည်။

### 1.2.1 Kubernetes က ကွန်ပျူတာ cluster တစ်ခုကို မည်သို့ ပြောင်းလဲပေးသည်ကို နားလည်ခြင်း

သင်၏ server များပေါ်တွင် Kubernetes ကို deploy လုပ်လိုက်သည့်အခါ data center အပေါ် အမြင်ပြောင်းလဲသွားပုံကို ပိုမိုအသေးစိတ် ကြည့်ကြပါစို့။

**Kubernetes သည် ကွန်ပျူတာ cluster များအတွက် operating system တစ်ခုနှင့်တူသည်**

Kubernetes ကို cluster အတွက် operating system တစ်ခုအဖြစ် မြင်ယောင်နိုင်ပါသည်။ နောက်ပုံသည် ကွန်ပျူတာတစ်လုံးပေါ်တွင် run နေသော operating system နှင့် ကွန်ပျူတာ cluster တစ်ခုပေါ်တွင် run နေသော Kubernetes ကြားရှိ တူညီမှုများကို သရုပ်ဖော်ထားပါသည်။

**ပုံ 1.8 Kubernetes သည် ကွန်ပျူတာ cluster အတွက် operating system တစ်ခုနှင့်တူသကဲ့သို့၊ Operating System သည် ကွန်ပျူတာအတွက် တစ်ခုဖြစ်သည်**

Operating system တစ်ခုသည် ကွန်ပျူတာ၏ အခြေခံလုပ်ဆောင်ချက်များဖြစ်သော ၎င်း၏ CPU များပေါ်သို့ process များကို schedule လုပ်ခြင်းနှင့် application နှင့် ကွန်ပျူတာ၏ hardware ကြားတွင် interface တစ်ခုအဖြစ် လုပ်ဆောင်ခြင်းကို ထောက်ပံ့ပေးသကဲ့သို့၊ Kubernetes သည် အောက်ခံကွန်ပျူတာ cluster ရှိ ကွန်ပျူတာတစ်လုံးချင်းစီပေါ်သို့ distributed application ၏ component များကို schedule လုပ်ပြီး၊ application နှင့် cluster ကြားတွင် interface တစ်ခုအဖြစ် လုပ်ဆောင်ပေးပါသည်။

၎င်းသည် application developer များကို ၎င်းတို့၏ application များတွင် infrastructure နှင့် ဆက်စပ်သော mechanism များကို implement လုပ်ရန် မလိုအပ်တော့ဘဲ၊ ၎င်းတို့ကို ပံ့ပိုးပေးရန် Kubernetes ကို အားကိုးစေပါသည်။ ၎င်းတွင် အောက်ပါအရာများ ပါဝင်သည်-

* **service discovery** - application များက အခြား application များကို ရှာဖွေပြီး ၎င်းတို့ ပံ့ပိုးပေးသော service များကို အသုံးပြုနိုင်စေသည့် mechanism တစ်ခု၊
* **horizontal scaling** - load အတက်အကျနှင့် လိုက်လျောညီထွေဖြစ်စေရန် သင်၏ application ကို replicate လုပ်ခြင်း၊
* **load-balancing** - application replica အားလုံးပေါ်သို့ load ကို ဖြန့်ဝေခြင်း၊
* **self-healing** - fail ဖြစ်သွားသော application များကို အလိုအလျောက် restart လုပ်ခြင်းနှင့် ၎င်းတို့၏ node များ fail ဖြစ်သွားပြီးနောက် ၎င်းတို့ကို healthy node များသို့ ရွှေ့ပြောင်းခြင်းဖြင့် system ကို ကောင်းမွန်စွာ ထိန်းသိမ်းခြင်း၊
* **leader election** - active instance fail ဖြစ်သွားပါက လွှဲပြောင်းယူရန် အသင့်ရှိနေစဉ်၊ application ၏ မည်သည့် instance သည် active ဖြစ်သင့်သည်ကို ဆုံးဖြတ်ပေးသော mechanism တစ်ခု။

ဤ feature များကို ပံ့ပိုးပေးရန် Kubernetes ကို အားကိုးခြင်းဖြင့်၊ application developer များသည် application များကို infrastructure နှင့် ပေါင်းစပ်ရန် အချိန်ဖြုန်းမည့်အစား အဓိက business logic ကို implement လုပ်ခြင်းအပေါ် အာရုံစိုက်နိုင်ပါသည်။

**Kubernetes သည် ကွန်ပျူတာ cluster တစ်ခုထဲသို့ မည်သို့ အံဝင်ခွင်ကျဖြစ်သနည်း**

Kubernetes ကို ကွန်ပျူတာ cluster တစ်ခုပေါ်သို့ deploy လုပ်ပုံ၏ ခိုင်မာသော ဥပမာတစ်ခုရရှိရန်၊ အောက်ပါပုံကို ကြည့်ပါ။

**ပုံ 1.9 Kubernetes cluster ရှိ ကွန်ပျူတာများကို Control Plane နှင့် Workload Plane အဖြစ် ခွဲခြားထားသည်**

သင်သည် စက်များအုပ်စုတစ်စုဖြင့် စတင်ပြီး ၎င်းတို့ကို အုပ်စုနှစ်စု - master နှင့် worker node များအဖြစ် ခွဲခြားလိုက်သည်။ Master node များသည် သင်၏ system ၏ ဦးနှောက်ကို ကိုယ်စားပြုပြီး cluster ကို ထိန်းချုပ်သည့် Kubernetes Control Plane ကို run မည်ဖြစ်ပြီး၊ ကျန်စက်များသည် သင်၏ application များ - သင်၏ workload များကို run မည်ဖြစ်သောကြောင့် Workload Plane ကို ကိုယ်စားပြုပါမည်။

> **မှတ်ချက်**
> Workload Plane ကို တစ်ခါတစ်ရံ Data Plane ဟု ရည်ညွှန်းသော်လည်း၊ ဤ plane သည် data များကို မဟုတ်ဘဲ application များကို host လုပ်သောကြောင့် ဤအသုံးအနှုန်းသည် ရှုပ်ထွေးစေနိုင်ပါသည်။ "plane" ဟူသော အသုံးအနှုန်းကြောင့်လည်း မရှုပ်ထွေးပါနှင့် - ဤအခြေအနေတွင် ၎င်းကို application များ run နေသော "မျက်နှာပြင်" အဖြစ် သင်စဉ်းစားနိုင်ပါသည်။

Non-production cluster များသည် master node တစ်လုံးတည်းကို အသုံးပြုနိုင်သော်လည်း၊ highly available cluster များသည် Control Plane ကို host လုပ်ရန် အနည်းဆုံး physical master node သုံးလုံးကို အသုံးပြုပါသည်။ Worker node အရေအတွက်သည် သင် deploy လုပ်မည့် application အရေအတွက်ပေါ်တွင် မူတည်ပါသည်။

**Cluster node အားလုံးသည် ကြီးမားသော deployment နေရာတစ်ခု ဖြစ်လာပုံ**

ကွန်ပျူတာများပေါ်တွင် Kubernetes ကို install လုပ်ပြီးနောက်၊ application deploy လုပ်သည့်အခါ ကွန်ပျူတာတစ်လုံးချင်းစီကို စဉ်းစားရန် မလိုအပ်တော့ပါ။ သင်၏ cluster တွင် worker node အရေအတွက် မည်မျှပင်ရှိစေကာမူ၊ ၎င်းတို့အားလုံးသည် သင်၏ application များကို deploy လုပ်သည့် နေရာတစ်ခုတည်း ဖြစ်လာပါသည်။ သင်သည် ၎င်းကို Kubernetes Control Plane မှ ပံ့ပိုးပေးသော Kubernetes API ကို အသုံးပြု၍ လုပ်ဆောင်ပါသည်။

**ပုံ 1.10 Kubernetes သည် cluster ကို တသမတ်တည်းဖြစ်သော deployment နေရာတစ်ခုအဖြစ် ဖော်ပြသည်**

Worker node အားလုံးသည် နေရာတစ်ခုတည်းဖြစ်လာသည်ဟု ကျွန်တော်ပြောသည့်အခါ၊ သင်သည် သေးငယ်သောစက်များစွာပေါ်တွင် ဖြန့်ကျက်ထားသော အလွန်ကြီးမားသည့် application တစ်ခုကို deploy လုပ်နိုင်သည်ဟု မထင်စေလိုပါ။ Kubernetes သည် ဤကဲ့သို့သော မျက်လှည့်များကို မလုပ်ဆောင်ပါ။ Application တစ်ခုစီသည် worker node တစ်ခုပေါ်တွင် အံဝင်နိုင်လောက်အောင် သေးငယ်ရပါမည်။

ကျွန်တော်ဆိုလိုသည်မှာ application များကို deploy လုပ်သည့်အခါ၊ ၎င်းတို့ မည်သည့် worker node တွင် အဆုံးသတ်သည်မှာ အရေးမကြီးပါ။ Kubernetes သည် နောက်ပိုင်းတွင် application ကို node တစ်ခုမှ အခြားတစ်ခုသို့ပင် ရွှေ့ပြောင်းနိုင်ပါသည်။ ထိုသို့ဖြစ်ပျက်သည့်အခါ သင်သတိပြုမိမည်မဟုတ်သလို၊ သင်ဂရုစိုက်ရန်လည်း မလိုအပ်ပါ။

### 1.2.2 Kubernetes အသုံးပြုခြင်း၏ အကျိုးကျေးဇူးများ

ကမ္ဘာတစ်ဝှမ်းရှိ အဖွဲ့အစည်းများစွာသည် ၎င်းတို့၏ data center များသို့ Kubernetes ကို အဘယ်ကြောင့် ကြိုဆိုခဲ့ကြသည်ကို သင်သိရှိပြီးဖြစ်သည်။ ယခု၊ ၎င်းက development နှင့် IT operations အဖွဲ့များနှစ်ဖွဲ့လုံးအတွက် ဆောင်ကျဉ်းပေးသော တိကျသည့် အကျိုးကျေးဇူးများကို ပိုမိုအသေးစိတ် ကြည့်ကြပါစို့။

**Application များကို ကိုယ်တိုင် deploy လုပ်နိုင်ခြင်း (Self-service deployment)**

Kubernetes သည် ၎င်း၏ worker node အားလုံးကို deployment မျက်နှာပြင်တစ်ခုတည်းအဖြစ် ဖော်ပြသောကြောင့်၊ သင်၏ application ကို မည်သည့် node သို့ deploy လုပ်သည်မှာ အရေးမကြီးတော့ပါ။ ၎င်းက developer များသည် node အရေအတွက် သို့မဟုတ် node တစ်ခုစီ၏ လက္ခဏာများအကြောင်း ဘာမှမသိသော်လည်း၊ application များကို ၎င်းတို့ကိုယ်တိုင် deploy လုပ်နိုင်သည်ဟု ဆိုလိုပါသည်။

ယခင်က၊ system administrator များသည် application တစ်ခုစီကို မည်သည့်နေရာတွင် ထားရှိသင့်သည်ကို ဆုံးဖြတ်သူများ ဖြစ်ကြသည်။ ဤတာဝန်ကို ယခုအခါ Kubernetes သို့ ချန်ထားခဲ့သည်။ ၎င်းသည် developer တစ်ဦးအား အခြားသူများကို အားမကိုးဘဲ application များကို deploy လုပ်နိုင်စေပါသည်။ Developer တစ်ဦးက application တစ်ခုကို deploy လုပ်သည့်အခါ၊ Kubernetes သည် application ၏ resource လိုအပ်ချက်များနှင့် node တစ်ခုစီတွင် ရရှိနိုင်သော resource များအပေါ် အခြေခံ၍ application ကို run ရန် အကောင်းဆုံး node ကို ရွေးချယ်ပေးပါသည်။

**Infrastructure အသုံးပြုမှုကို ပိုမိုကောင်းမွန်စေခြင်းဖြင့် ကုန်ကျစရိတ်လျှော့ချခြင်း**

သင်၏ application မည်သည့် node တွင် ရောက်ရှိသည်ကို သင်ဂရုမစိုက်ပါက၊ ၎င်းကို သင်စိုးရိမ်စရာမလိုဘဲ အချိန်မရွေး အခြား node သို့ ရွှေ့ပြောင်းနိုင်သည်ဟု ဆိုလိုပါသည်။ Kubernetes သည် တစ်စုံတစ်ဦးက deploy လုပ်လိုသော ပိုကြီးသည့် application တစ်ခုအတွက် နေရာပြုလုပ်ရန် ၎င်းကို လုပ်ဆောင်ရန် လိုအပ်နိုင်ပါသည်။ Application များကို ရွှေ့ပြောင်းနိုင်သည့် ဤစွမ်းရည်သည် application များကို တင်းကျပ်စွာ စုစည်းထားနိုင်စေပြီး node များ၏ resource များကို အကောင်းဆုံးနည်းလမ်းဖြင့် အသုံးပြုနိုင်စေပါသည်။

> **မှတ်ချက်**
> အခန်း ၁၇ တွင် Kubernetes က application တစ်ခုစီကို မည်သည့်နေရာတွင် ထားရှိရန် ဆုံးဖြတ်ပုံနှင့် သင်မည်သို့ ဆုံးဖြတ်ချက်ကို လွှမ်းမိုးနိုင်ပုံအကြောင်း ပိုမိုလေ့လာရပါမည်။

အကောင်းဆုံးပေါင်းစပ်မှုများကို ရှာဖွေခြင်းသည် စိန်ခေါ်မှုဖြစ်ပြီး အချိန်ကုန်နိုင်သည်၊ အထူးသဖြင့် သင်တွင် application component များစွာနှင့် ၎င်းတို့ကို deploy လုပ်နိုင်သည့် server node များစွာရှိသည့်အခါကဲ့သို့ ဖြစ်နိုင်ခြေရှိသော option အရေအတွက် ကြီးမားသည့်အခါတွင် ဖြစ်သည်။ ကွန်ပျူတာများသည် ဤတာဝန်ကို လူသားများထက် ပိုမိုကောင်းမွန်ပြီး ပိုမိုမြန်ဆန်စွာ လုပ်ဆောင်နိုင်ပါသည်။ Kubernetes သည် ၎င်းကို အလွန်ကောင်းမွန်စွာ လုပ်ဆောင်ပါသည်။ မတူညီသော application များကို တူညီသောစက်များပေါ်တွင် ပေါင်းစပ်ခြင်းဖြင့်၊ Kubernetes သည် သင်၏ hardware infrastructure ၏ အသုံးပြုမှုကို တိုးတက်စေသောကြောင့် သင်သည် application ပိုမयोကို server နည်းနည်းဖြင့် run နိုင်ပါသည်။

**ပြောင်းလဲနေသော load နှင့် အလိုအလျောက် လိုက်လျောညီထွေဖြစ်စေခြင်း**

သင်၏ deploy လုပ်ထားသော application များကို စီမံခန့်ခွဲရန် Kubernetes ကို အသုံးပြုခြင်းသည် operations အဖွဲ့သည် ရုတ်တရက် load အထွတ်အထိပ်သို့ ရောက်ရှိမှုကို တုံ့ပြန်ရန်အတွက် application တစ်ခုစီ၏ load ကို အဆက်မပြတ် စောင့်ကြည့်ရန် မလိုအပ်တော့ဟု ဆိုလိုပါသည်။ Kubernetes သည် ဤအရာကိုလည်း ဂရုစိုက်ပါသည်။ ၎င်းသည် application တစ်ခုစီမှ သုံးစွဲသော resource များနှင့် အခြား metric များကို စောင့်ကြည့်နိုင်ပြီး တိုးများလာသော load သို့မဟုတ် resource အသုံးပြုမှုကို ကိုင်တွယ်ရန်အတွက် application တစ်ခုစီ၏ run နေသော instance အရေအတွက်ကို ချိန်ညှိနိုင်ပါသည်။

Cloud infrastructure ပေါ်တွင် Kubernetes ကို run သည့်အခါ၊ ၎င်းသည် cloud provider ၏ API မှတစ်ဆင့် နောက်ထပ် node များကို provision လုပ်ခြင်းဖြင့် သင်၏ cluster အရွယ်အစားကိုပင် တိုးမြှင့်နိုင်ပါသည်။ ဤနည်းဖြင့်၊ သင်၏ application များ၏ နောက်ထပ် instance များကို run ရန် နေရာဘယ်တော့မှ မကုန်တော့ပါ။

**Application များကို ချောမွေ့စွာ run နေစေရန် ထိန်းသိမ်းခြင်း**

Kubernetes သည် သင်၏ application များ ချောမွေ့စွာ run နေစေရန် အစွမ်းကုန် ကြိုးစားပါသည်။ အကယ်၍ သင်၏ application crash ဖြစ်သွားပါက၊ Kubernetes သည် ၎င်းကို အလိုအလျောက် restart လုပ်ပေးပါမည်။ ထို့ကြောင့် သင်တွင် နာရီအနည်းငယ်ထက် ပို run ပြီးနောက် memory ကုန်သွားသော ချို့ယွင်းနေသည့် application တစ်ခုရှိနေသော်လည်း၊ Kubernetes သည် ဤအခြေအနေတွင် ၎င်းကို အလိုအလျောက် restart လုပ်ခြင်းဖြင့် သင်၏ application သည် ၎င်း၏ user များသို့ service ကို ဆက်လက် ပံ့ပိုးပေးနေကြောင်း သေချာစေပါမည်။

Kubernetes သည် အထက်တွင်ဖော်ပြထားသော software error မျိုးကို ကိုင်တွယ်ဖြေရှင်းပေးသည့် self-healing system တစ်ခုဖြစ်သော်လည်း၊ ၎င်းသည် hardware failure များကိုလည်း ကိုင်တွယ်ပါသည်။ Cluster အရွယ်အစား ကြီးထွားလာသည်နှင့်အမျှ၊ node failure အကြိမ်နှုန်းသည်လည်း တိုးများလာပါသည်။ ဥပမာအားဖြင့်၊ node တစ်ရာရှိသော cluster တစ်ခုတွင် node တစ်ခုစီအတွက် MTBF (mean-time-between-failure) သည် ရက် ၁၀၀ ဖြစ်ပါက၊ သင်သည် တစ်နေ့လျှင် node တစ်လုံး fail ဖြစ်မည်ဟု မျှော်လင့်နိုင်ပါသည်။

Node တစ်ခု fail ဖြစ်သွားသည့်အခါ၊ Kubernetes သည် application များကို ကျန်ရှိသော healthy node များသို့ အလိုအလျောက် ရွှေ့ပြောင်းပေးပါသည်။ Operations အဖွဲ့သည် application ကို လူကိုယ်တိုင် ရွှေ့ပြောင်းရန် မလိုအပ်တော့ဘဲ၊ node ကိုယ်တိုင်ကို ပြုပြင်ပြီး ရရှိနိုင်သော hardware resource များ၏ pool သို့ ပြန်လည်ထည့်သွင်းခြင်းအပေါ် အာရုံစိုက်နိုင်ပါသည်။

အကယ်၍ သင်၏ infrastructure တွင် fail ဖြစ်သွားသော node မပါဘဲ ပုံမှန် system လည်ပတ်မှုကို ခွင့်ပြုရန် လုံလောက်သော free resource များရှိပါက၊ operations အဖွဲ့သည် failure ကို ချက်ချင်းတုံ့ပြန်ရန်ပင် မလိုအပ်ပါ။ ၎င်းသည် ညသန်းခေါင်တွင် ဖြစ်ပွားပါက၊ operations အဖွဲ့မှ မည်သူမျှ နိုးထရန်ပင် မလိုအပ်ပါ။ ၎င်းတို့သည် အေးချမ်းစွာ အိပ်စက်နိုင်ပြီး ပုံမှန်အလုပ်ချိန်အတွင်း fail ဖြစ်သွားသော node ကို ကိုင်တွယ်ဖြေရှင်းနိုင်ပါသည်။

**Application development ကို ရိုးရှင်းစေခြင်း**

ယခင်အပိုင်းတွင် ဖော်ပြခဲ့သော တိုးတက်မှုများသည် အဓိကအားဖြင့် application deployment နှင့် သက်ဆိုင်သည်။ သို့သော် application development process ကော အသို့နည်း။ Kubernetes သည် ၎င်းတို့အတွက် တစ်စုံတစ်ရာ ယူဆောင်လာပါသလား။ သေချာပေါက် ယူဆောင်လာပါသည်။

ယခင်က ဖော်ပြခဲ့သည့်အတိုင်း၊ Kubernetes သည် သင်၏ application များတွင် implement လုပ်ရမည့် infrastructure နှင့် သက်ဆိုင်သော service များကို ကမ်းလှမ်းပါသည်။ ၎င်းတွင် distributed application တစ်ခုရှိ service များနှင့်/သို့မဟုတ် peer များကို ရှာဖွေတွေ့ရှိခြင်း၊ leader election၊ ဗဟိုချုပ်ကိုင်ထားသော application configuration နှင့် အခြားအရာများ ပါဝင်သည်။ Kubernetes သည် application ကို Kubernetes-agnostic (Kubernetes နှင့် မသက်ဆိုင်သော) အဖြစ် ထားရှိစဉ် ဤအရာကို ပံ့ပိုးပေးသော်လည်း၊ လိုအပ်သည့်အခါ၊ application များသည် ၎င်းတို့၏ environment အကြောင်း အသေးစိတ်အချက်အလက်များ ရယူရန်အတွက် Kubernetes API ကို query လုပ်နိုင်ပါသည်။ ၎င်းတို့သည် environment ကို ပြောင်းလဲရန် API ကိုလည်း အသုံးပြုနိုင်ပါသည်။

### 1.2.3 Kubernetes cluster တစ်ခု၏ architecture

သင်သိရှိပြီးသည့်အတိုင်း၊ Kubernetes cluster တစ်ခုသည် အုပ်စုနှစ်စုခွဲထားသော node များဖြင့် ဖွဲ့စည်းထားသည်-

* **Master node** များအစု - ၎င်းတို့သည် system ၏ ဦးနှောက်ဖြစ်သော Control Plane component များကို host လုပ်ပြီး၊ cluster တစ်ခုလုံးကို ထိန်းချုပ်ပါသည်။
* **Worker node** များအစု - ၎င်းတို့သည် Workload Plane ကို ဖွဲ့စည်းပြီး၊ သင်၏ workload များ (သို့မဟုတ် application များ) run သည့်နေရာ ဖြစ်ပါသည်။

အောက်ပါပုံသည် plane နှစ်ခုနှင့် ၎င်းတို့ပါဝင်သော node အမျိုးမျိုးကို ပြသထားပါသည်။

**ပုံ 1.11 Kubernetes cluster တစ်ခုကို ဖွဲ့စည်းထားသော plane နှစ်ခု**

Plane နှစ်ခု၊ ထို့ကြောင့် node အမျိုးအစားနှစ်ခုသည် မတူညီသော Kubernetes component များကို run ကြသည်။ စာအုပ်၏ နောက်အပိုင်းနှစ်ပိုင်းသည် ၎င်းတို့ကို မိတ်ဆက်ပြီး ၎င်းတို့၏ လုပ်ဆောင်ချက်များကို အသေးစိတ်မသွားဘဲ အကျဉ်းချုံ့ဖော်ပြပါမည်။ ဤ component များကို စာအုပ်၏ နောက်တစ်ပိုင်းတွင် Kubernetes ၏ အခြေခံ concept များကို ရှင်းပြသည့်အခါ အကြိမ်များစွာ ဖော်ပြပါမည်။ Component များနှင့် ၎င်းတို့၏ အတွင်းပိုင်းကို နက်နက်နဲနဲ လေ့လာခြင်းသည် စာအုပ်၏ တတိယပိုင်းတွင် ပါဝင်ပါသည်။

**Control Plane component များ**

Control Plane သည် cluster ကို ထိန်းချုပ်သောအရာဖြစ်သည်။ ၎င်းသည် master node တစ်လုံးပေါ်တွင် run သော သို့မဟုတ် high availability ကို သေချာစေရန် master node များစွာပေါ်တွင် replicated လုပ်ထားသော component များစွာဖြင့် ဖွဲ့စည်းထားပါသည်။ Control Plane ၏ component များကို အောက်ပါပုံတွင် ပြသထားပါသည်။

**ပုံ 1.12 Kubernetes Control Plane ၏ component များ**

ဤသည်တို့မှာ component များနှင့် ၎င်းတို့၏ လုပ်ဆောင်ချက်များ ဖြစ်သည်-

* **Kubernetes API Server** သည် RESTful Kubernetes API ကို ဖော်ပြပါသည်။ Cluster ကို အသုံးပြုသော engineer များနှင့် အခြား Kubernetes component များသည် ဤ API မှတစ်ဆင့် object များကို ဖန်တီးကြသည်။
* **etcd** distributed datastore သည် API မှတစ်ဆင့် သင်ဖန်တီးသော object များကို သိမ်းဆည်းပေးသည်၊ အဘယ်ကြောင့်ဆိုသော် API Server ကိုယ်တိုင်သည် stateless ဖြစ်သောကြောင့်ဖြစ်သည်။ Server သည် etcd နှင့် စကားပြောသော တစ်ခုတည်းသော component ဖြစ်သည်။
* **Scheduler** သည် application instance တစ်ခုစီကို မည်သည့် worker node ပေါ်တွင် run သင့်သည်ကို ဆုံးဖြတ်ပေးသည်။
* **Controller** များသည် API မှတစ်ဆင့် သင်ဖန်တီးသော object များကို အသက်ဝင်စေသည်။ ၎င်းတို့အများစုသည် အခြား object များကိုသာ ဖန်တီးကြသော်လည်း၊ အချို့သည် external system များ (ဥပမာ၊ cloud provider နှင့် ၎င်း၏ API မှတစ်ဆင့်) နှင့်လည်း ဆက်သွယ်ကြသည်။

Control Plane ၏ component များသည် cluster ၏ state ကို ထိန်းသိမ်းပြီး ထိန်းချုပ်သော်လည်း၊ ၎င်းတို့သည် သင်၏ application များကို မ run ပါ။ ၎င်းကို (worker) node များက လုပ်ဆောင်ပါသည်။

**Worker node component များ**

Worker node များသည် သင်၏ application များ run သော ကွန်ပျူတာများဖြစ်သည်။ ၎င်းတို့သည် cluster ၏ Workload Plane ကို ဖွဲ့စည်းသည်။ Application များအပြင်၊ Kubernetes component များစွာသည်လည်း ဤ node များပေါ်တွင် run ကြသည်။ ၎င်းတို့သည် သင်၏ application များကြားတွင် run ခြင်း၊ စောင့်ကြည့်ခြင်းနှင့် connectivity ပံ့ပိုးပေးခြင်း တာဝန်ကို လုပ်ဆောင်ကြသည်။ ၎င်းတို့ကို အောက်ပါပုံတွင် ပြသထားပါသည်။

**ပုံ 1.13 node တစ်ခုစီတွင် run သော Kubernetes component များ**

Node တစ်ခုစီသည် အောက်ပါ component အစုံကို run သည်-

* **Kubelet** - ၎င်းသည် API server နှင့် စကားပြောပြီး ၎င်း၏ node ပေါ်တွင် run နေသော application များကို စီမံခန့်ခွဲသည့် agent တစ်ခုဖြစ်သည်။ ၎င်းသည် ဤ application များနှင့် node ၏ status ကို API မှတစ်ဆင့် report လုပ်ပါသည်။
* **Container Runtime** - ၎င်းသည် Docker သို့မဟုတ် Kubernetes နှင့် တွဲဖက်အသုံးပြုနိုင်သော အခြား runtime တစ်ခုခု ဖြစ်နိုင်ပါသည်။ ၎င်းသည် Kubelet မှ ညွှန်ကြားသည့်အတိုင်း သင်၏ application များကို container များထဲတွင် run ပေးသည်။
* **Kubernetes Service Proxy (Kube Proxy)** - ၎င်းသည် application များကြားရှိ network traffic ကို load-balance လုပ်ပေးသည်။ ၎င်း၏အမည်က traffic သည် ၎င်းမှတစ်ဆင့် စီးဆင်းသည်ဟု ညွှန်ပြသော်လည်း၊ ယခုအခါ ထိုသို့မဟုတ်တော့ပါ။ အဘယ်ကြောင့်ဆိုသည်ကို အခန်း ၁၄ တွင် သင်လေ့လာရပါမည်။

**Add-on component များ**

Kubernetes cluster အများစုတွင် အခြား component များစွာလည်း ပါဝင်သည်။ ၎င်းတွင် DNS server, network plugin များ၊ logging agent များနှင့် အခြားများစွာ ပါဝင်သည်။ ၎င်းတို့သည် များသောအားဖြင့် worker node များပေါ်တွင် run ကြသော်လည်း၊ master ပေါ်တွင် run ရန်လည်း configure လုပ်နိုင်ပါသည်။

**Architecture ကို ပိုမိုနက်ရှိုင်းစွာ နားလည်ခြင်း**

ယခုလောလောဆယ်တွင်၊ ဤ component များ၏ အမည်များနှင့် ၎င်းတို့၏ လုပ်ဆောင်ချက်ကို မထင်မရှား သိရှိထားရန်သာ ကျွန်တော်မျှော်လင့်သည်၊ အဘယ်ကြောင့်ဆိုသော် ၎င်းတို့ကို နောက်အခန်းများတစ်လျှောက်လုံး အကြိမ်များစွာ ဖော်ပြမည်ဖြစ်သောကြောင့်ဖြစ်သည်။ ဤအခန်းများတွင် ၎င်းတို့အကြောင်း အနည်းငယ်စီ လေ့လာရမည်ဖြစ်သော်လည်း၊ အခန်း ၁၄ တွင် ၎င်းတို့ကို ပိုမိုအသေးစိတ် ရှင်းပြပါမည်။

### 1.2.4 Kubernetes သည် application တစ်ခုကို မည်သို့ run သနည်း**

Kubernetes ကို ဖွဲ့စည်းထားသော component များကို ခြုံငုံသုံးသပ်ပြီးနောက်၊ Kubernetes တွင် application တစ်ခုကို deploy လုပ်ပုံကို နောက်ဆုံးတွင် ရှင်းပြနိုင်ပါပြီ။

**သင်၏ application ကို သတ်မှတ်ဖော်ပြခြင်း**

Kubernetes ရှိ အရာအားလုံးကို object တစ်ခုဖြင့် ကိုယ်စားပြုသည်။ သင်သည် ဤ object များကို Kubernetes API မှတစ်ဆင့် ဖန်တီးပြီး ပြန်လည်ရယူသည်။ သင်၏ application သည် ဤ object အမျိုးအစားများစွာဖြင့် ဖွဲ့စည်းထားသည် - အမျိုးအစားတစ်ခုသည် application deployment တစ်ခုလုံးကို ကိုယ်စားပြုပြီး၊ အခြားတစ်ခုသည် သင်၏ application ၏ run နေသော instance တစ်ခုကို ကိုယ်စားပြုသည်၊ အခြားတစ်ခုသည် ဤ instance များအစုမှ ပံ့ပိုးပေးသော service ကို ကိုယ်စားပြုပြီး ၎င်းတို့ကို IP address တစ်ခုတည်းတွင် ရောက်ရှိနိုင်စေသည်၊ နှင့် အခြားများစွာ ရှိသေးသည်။

ဤအမျိုးအစားအားလုံးကို စာအုပ်၏ ဒုတိယပိုင်းတွင် အသေးစိတ် ရှင်းပြထားသည်။ ယခုအချိန်တွင်၊ သင်၏ application ကို object အမျိုးအစားများစွာဖြင့် သတ်မှတ်ဖော်ပြသည်ကို သိရှိထားရန် လုံလောက်ပါသည်။ ဤ object များကို များသောအားဖြင့် YAML သို့မဟုတ် JSON format ဖြင့် manifest file တစ်ခု သို့မဟုတ် တစ်ခုထက်ပို၍ သတ်မှတ်ဖော်ပြပါသည်။

**ပုံ 1.14 application တစ်ခုကို Kubernetes သို့ deploy လုပ်ခြင်း**

Application ကို deploy လုပ်သည့်အခါ ဤလုပ်ဆောင်ချက်များ ဖြစ်ပွားသည်-

1.  သင်သည် application manifest ကို Kubernetes API သို့ submit လုပ်သည်။ API Server သည် manifest တွင် သတ်မှတ်ထားသော object များကို etcd သို့ ရေးသားသည်။
2.  Controller တစ်ခုသည် အသစ်ဖန်တီးထားသော object များကို သတိပြုမိပြီး object အသစ်များစွာ - application instance တစ်ခုစီအတွက် တစ်ခု - ကို ဖန်တီးသည်။
3.  Scheduler သည် instance တစ်ခုစီအတွက် node တစ်ခုကို သတ်မှတ်ပေးသည်။
4.  Kubelet သည် instance တစ်ခုကို Kubelet ၏ node သို့ သတ်မှတ်ပေးထားသည်ကို သတိပြုမိသည်။ ၎င်းသည် Container Runtime မှတစ်ဆင့် application instance ကို run သည်။
5.  Kube Proxy သည် application instance များသည် client များထံမှ connection များကို လက်ခံရန် အသင့်ဖြစ်နေပြီကို သတိပြုမိပြီး ၎င်းတို့အတွက် load balancer တစ်ခုကို configure လုပ်သည်။
6.  Kubelet များနှင့် Controller များသည် system ကို စောင့်ကြည့်ပြီး application များကို run နေစေရန် ထိန်းသိမ်းသည်။

## 1.3 သင်၏အဖွဲ့အစည်းသို့ Kubernetes ကို မိတ်ဆက်ခြင်း

ဤအခန်းကို ပိတ်သိမ်းရန်၊ သင်၏ ကိုယ်ပိုင် IT environment တွင် Kubernetes ကို မိတ်ဆက်ရန် ဆုံးဖြတ်ပါက သင့်အတွက် ရရှိနိုင်သော option များကို ကြည့်ကြပါစို့။

### 1.3.1 Kubernetes ကို on-premises နှင့် cloud တွင် run ခြင်း**

သင်၏ application များကို Kubernetes ပေါ်တွင် run လိုပါက၊ ၎င်းတို့ကို local တွင်၊ သင်၏အဖွဲ့အစည်း၏ ကိုယ်ပိုင် infrastructure (on-premises) တွင် သို့မဟုတ် အဓိက cloud provider တစ်ခုခုတွင်၊ သို့မဟုတ် နှစ်မျိုးလုံး - hybrid cloud solution တွင် run လိုသည်ကို ဆုံးဖြတ်ရပါမည်။

**Kubernetes ကို on-premises တွင် run ခြင်း**

စည်းမျဉ်းများအရ application များကို site ပေါ်တွင် run ရန် လိုအပ်ပါက သင်၏ ကိုယ်ပိုင် infrastructure တွင် Kubernetes ကို run ခြင်းသည် သင်၏ တစ်ခုတည်းသော option ဖြစ်နိုင်ပါသည်။ ၎င်းသည် များသောအားဖြင့် သင် Kubernetes ကို ကိုယ်တိုင် စီမံခန့်ခွဲရမည်ဟု ဆိုလိုသော်လည်း၊ ထိုအကြောင်းကို နောက်ပိုင်းတွင် ပြောပါမည်။

Kubernetes သည် သင်၏ bare-metal machine များပေါ်တွင် တိုက်ရိုက် သို့မဟုတ် သင်၏ data center ရှိ virtual machine များတွင် run နိုင်ပါသည်။ မည်သို့ပင်ဖြစ်စေ၊ သင်သည် cloud provider မှ ပံ့ပိုးပေးသော virtual machine များတွင် run သည့်အခါကဲ့သို့ သင်၏ cluster ကို လွယ်ကူစွာ scale လုပ်နိုင်မည် မဟုတ်ပါ။

**Kubernetes ကို cloud တွင် deploy လုပ်ခြင်း**

သင့်တွင် on-premises infrastructure မရှိပါက၊ Kubernetes ကို cloud တွင် run ရန်မှလွဲ၍ အခြားရွေးချယ်စရာမရှိပါ။ ၎င်းတွင် လိုအပ်ပါက အချိန်တိုအတွင်း သင်၏ cluster ကို scale လုပ်နိုင်သည့် အားသာချက်ရှိသည်။ အစောပိုင်းက ဖော်ပြခဲ့သည့်အတိုင်း၊ Kubernetes ကိုယ်တိုင်သည် သင် deploy လုပ်လိုသော application အားလုံးကို run ရန် လက်ရှိ cluster အရွယ်အစား မလုံလောက်တော့သည့်အခါ နောက်ထပ် virtual machine များကို provision လုပ်ရန် cloud provider ကို တောင်းဆိုနိုင်ပါသည်။

Workload အရေအတွက် လျော့နည်းသွားပြီး အချို့ worker node များတွင် run နေသော workload များမရှိတော့သည့်အခါ၊ Kubernetes သည် သင်၏ လည်ပတ်မှုကုန်ကျစရိတ်များကို လျှော့ချရန်အတွက် ဤ node များ၏ virtual machine များကို ဖျက်ဆီးရန် cloud provider ကို တောင်းဆိုနိုင်ပါသည်။ Cluster ၏ ဤ elasticity သည် cloud တွင် Kubernetes ကို run ခြင်း၏ အဓိကအကျိုးကျေးဇူးများထဲမှ တစ်ခုဖြစ်သည်မှာ သေချာပါသည်။

**Hybrid cloud solution ကို အသုံးပြုခြင်း**

ပိုမိုရှုပ်ထွေးသော option မှာ Kubernetes ကို on-premises တွင် run ပြီး၊ ၎င်းကို cloud သို့လည်း ပျံ့နှံ့ခွင့်ပြုခြင်းဖြစ်သည်။ သင်၏ ကိုယ်ပိုင် data center ၏ capacity ကို ကျော်လွန်သွားပါက cloud တွင် နောက်ထပ် node များကို provision လုပ်ရန် Kubernetes ကို configure လုပ်နိုင်ပါသည်။ ဤနည်းဖြင့်၊ သင်သည် နှစ်မျိုးလုံး၏ အကောင်းဆုံးကို ရရှိပါသည်။ အချိန်အများစုတွင်၊ သင်၏ application များသည် virtual machine ငှားရမ်းခ ကုန်ကျစရိတ်မရှိဘဲ local တွင် run နေသော်လည်း၊ တစ်နှစ်လျှင် အကြိမ်အနည်းငယ်သာ ဖြစ်ပေါ်နိုင်သော load အထွတ်အထိပ်သို့ ရောက်ရှိသည့် အချိန်တိုများတွင်၊ သင်၏ application များသည် cloud ရှိ အပို resource များကို အသုံးပြုခြင်းဖြင့် အပို load ကို ကိုင်တွယ်ဖြေရှင်းနိုင်ပါသည်။

သင်၏ use-case က လိုအပ်ပါက၊ Kubernetes cluster တစ်ခုကို cloud provider များစွာ သို့မဟုတ် ဖော်ပြခဲ့သော option များ၏ ပေါင်းစပ်မှုတစ်ခုခုတွင်လည်း run နိုင်ပါသည်။ ၎င်းကို control plane တစ်ခုတည်းဖြင့် သို့မဟုတ် နေရာတစ်ခုစီတွင် control plane တစ်ခုဖြင့် လုပ်ဆောင်နိုင်ပါသည်။

### 1.3.2 Kubernetes ကို ကိုယ်တိုင် စီမံခန့်ခွဲမလား၊ မစီမံခန့်ခွဲဘူးလား**

သင်၏အဖွဲ့အစည်းတွင် Kubernetes ကို မိတ်ဆက်ရန် စဉ်းစားနေပါက၊ သင်ဖြေဆိုရန် လိုအပ်သော အရေးကြီးဆုံးမေးခွန်းမှာ Kubernetes ကို ကိုယ်တိုင် စီမံခန့်ခွဲမည်လား သို့မဟုတ် အခြားသူတစ်ဦးက သင့်အတွက် စီမံခန့်ခွဲပေးသည့် Kubernetes-as-a-Service အမျိုးအစား ဝန်ဆောင်မှုကို အသုံးပြုမည်လား ဆိုသည်ပင်ဖြစ်သည်။

**Kubernetes ကို ကိုယ်တိုင် စီမံခန့်ခွဲခြင်း**

သင်သည် application များကို on-premises တွင် run ပြီးဖြစ်ပြီး production-ready Kubernetes cluster တစ်ခု run ရန် လုံလောက်သော hardware ရှိပါက၊ သင်၏ ပထမဆုံး စိတ်ကူးသည် ၎င်းကို ကိုယ်တိုင် deploy လုပ်ပြီး စီမံခန့်ခွဲရန် ဖြစ်နိုင်ပါသည်။ Kubernetes community ရှိ မည်သူ့ကိုမဆို ဤသည်မှာ အကြံကောင်းဟုတ်မဟုတ် မေးပါက၊ သင်သည် များသောအားဖြင့် "မဟုတ်" ဟု အလွန်ပြတ်သားသော အဖြေကို ရရှိပါလိမ့်မည်။

Kubernetes သည် အလွန်ကြီးမားသော နောက်ထပ် ရှုပ်ထွေးမှုများကို ယူဆောင်လာပါသည်။ Kubernetes cluster တစ်ခု run လိုသူတိုင်းသည် ၎င်း၏ အတွင်းပိုင်း လုပ်ဆောင်ပုံများကို နက်နက်နဲနဲ ရင်းနှီးကျွမ်းဝင်ရပါမည်။

**Cloud ရှိ managed Kubernetes cluster ကို အသုံးပြုခြင်း**

Kubernetes ကို အသုံးပြုခြင်းသည် ၎င်းကို စီမံခန့်ခွဲခြင်းထက် ဆယ်ဆ ပိုလွယ်ကူပါသည်။ အဓိက cloud provider အများစုသည် ယခုအခါ Kubernetes-as-a-Service ကို ကမ်းလှမ်းပါသည်။ ၎င်းတို့သည် Kubernetes နှင့် ၎င်း၏ component များကို စီမံခန့်ခွဲခြင်းကို ဂရုစိုက်ပြီး၊ သင်သည် cloud provider က ကမ်းလှမ်းသော အခြား API များကဲ့သို့ Kubernetes API ကို ရိုးရှင်းစွာ အသုံးပြုရုံသာ ဖြစ်သည်။

ထိပ်တန်း managed Kubernetes ဝန်ဆောင်မှုများတွင် အောက်ပါတို့ ပါဝင်သည်-

* Google Kubernetes Engine (GKE)
* Azure Kubernetes Service (AKS)
* Amazon Elastic Kubernetes Service (EKS)
* IBM Cloud Kubernetes Service
* Red Hat OpenShift Online and Dedicated
* VMware Cloud PKS
* Alibaba Cloud Container Service for Kubernetes (ACK)

ဤစာအုပ်၏ ပထမတစ်ဝက်သည် Kubernetes ကို အသုံးပြုခြင်းကိုသာ အာရုံစိုက်ပါသည်။ သင်သည် local development cluster တစ်ခုနှင့် managed GKE cluster တစ်ခုပေါ်တွင် လေ့ကျင့်ခန်းများကို run ရပါမည်၊ အဘယ်ကြောင့်ဆိုသော် ၎င်းသည် အသုံးပြုရန် အလွယ်ကူဆုံးနှင့် အကောင်းဆုံး user experience ကို ကမ်းလှမ်းသည်ဟု ကျွန်တော်တွေ့ရှိသောကြောင့်ဖြစ်သည်။ စာအုပ်၏ ဒုတိယပိုင်းသည် Kubernetes ကို စီမံခန့်ခွဲရန်အတွက် ခိုင်မာသော အခြေခံကို ပေးသော်လည်း၊ ၎င်းကို အမှန်တကယ် ကျွမ်းကျင်ရန်အတွက်၊ သင်သည် နောက်ထပ် အတွေ့အကြုံများ ရယူရန် လိုအပ်ပါလိမ့်မည်။

### 1.3.3 vanilla သို့မဟုတ် extended Kubernetes ကို အသုံးပြုခြင်း**

နောက်ဆုံးမေးခွန်းမှာ Kubernetes ၏ vanilla open-source version ကို အသုံးပြုမည်လား သို့မဟုတ် extended, enterprise-quality Kubernetes product တစ်ခုကို အသုံးပြုမည်လား ဆိုသည်ပင်ဖြစ်သည်။

**Kubernetes ၏ vanilla version ကို အသုံးပြုခြင်း**

Kubernetes ၏ open-source version ကို community မှ ထိန်းသိမ်းပြီး Kubernetes development ၏ ရှေ့တန်းကို ကိုယ်စားပြုသည်။ ၎င်းသည် အခြား option များကဲ့သို့ တည်ငြိမ်မည်မဟုတ်ဟုလည်း ဆိုလိုပါသည်။ ၎င်းတွင် ကောင်းမွန်သော security default များလည်း ချို့တဲ့နိုင်ပါသည်။ Vanilla version ကို deploy လုပ်ခြင်းသည် production use အတွက် အရာအားလုံးကို set up လုပ်ရန် fine tuning များစွာ လိုအပ်ပါသည်။

**Enterprise-grade Kubernetes distribution များကို အသုံးပြုခြင်း**

Production တွင် Kubernetes ကို အသုံးပြုရန် ပိုမိုကောင်းမွန်သော option မှာ OpenShift သို့မဟုတ် Rancher ကဲ့သို့သော enterprise-quality Kubernetes distribution တစ်ခုကို အသုံးပြုခြင်းဖြစ်သည်။ ပိုမိုကောင်းမွန်သော default များမှ ပံ့ပိုးပေးသော တိုးမြှင့်ထားသော security နှင့် performance အပြင်၊ ၎င်းတို့သည် upstream Kubernetes API တွင် ပံ့ပိုးပေးသော object type များအပြင် နောက်ထပ် object type များကို ကမ်းလှမ်းပါသည်။ ဥပမာအားဖြင့်၊ vanilla Kubernetes တွင် cluster user များကို ကိုယ်စားပြုသော object type များ မပါဝင်သော်လည်း၊ commercial distribution များတွင် ပါဝင်သည်။ ၎င်းတို့သည် Kubernetes ပေါ်တွင် လူသိများသော third-party application များကို deploy လုပ်ပြီး စီမံခန့်ခွဲရန်အတွက် နောက်ထပ် software tool များကိုလည်း ပံ့ပိုးပေးပါသည်။

### 1.3.4 Kubernetes ကို အသုံးပြုသင့်ပါသလား။

ဤအခန်းသည် သင့်အား Kubernetes အပေါ် စိတ်လှုပ်ရှားစေပြီး ၎င်းကို သင်၏ IT stack ထဲသို့ ညှစ်ထည့်ရန် မစောင့်နိုင်တော့ဟု မျှော်လင့်ပါသည်။ သို့သော် ဤအခန်းကို ကောင်းမွန်စွာ ပိတ်သိမ်းရန်၊ Kubernetes ကို မိတ်ဆက်ခြင်းသည် အကြံကောင်းမဟုတ်သည့်အခါ အကြောင်း တစ်ခွန်းနှစ်ခွန်း ပြောရန် လိုအပ်ပါသည်။

**သင်၏ workload များသည် အလိုအလျောက် စီမံခန့်ခွဲမှု လိုအပ်ပါသလား။**

သင်ရိုးသားရန် လိုအပ်သော ပထမဆုံးအချက်မှာ သင်၏ application များ၏ စီမံခန့်ခွဲမှုကို အလိုအလျောက် လုပ်ဆောင်ရန် လိုအပ်ခြင်း ရှိမရှိပင်ဖြစ်သည်။ အကယ်၍ သင်၏ application သည် ကြီးမားသော monolith တစ်ခုဖြစ်ပါက၊ သင်သည် Kubernetes ကို သေချာပေါက် မလိုအပ်ပါ။

သင်သည် microservice များကို deploy လုပ်နေသော်လည်း၊ Kubernetes ကို အသုံးပြုခြင်းသည် အကောင်းဆုံး option မဖြစ်နိုင်ပါ၊ အထူးသဖြင့် သင်၏ microservice အရေအတွက် အလွန်နည်းပါက ဖြစ်သည်။ အခြား factor များကလည်း ဆုံးဖြတ်ချက်ကို လွှမ်းမိုးသောကြောင့်၊ အတိုင်းအတာများ မည်သည့်အချိန်တွင် ကျော်လွန်သွားသည်ကို တိကျသော အရေအတွက် ပေးရန် ခက်ခဲပါသည်။ သို့သော် သင်၏ system တွင် microservice ငါးခုထက်နည်းပါက၊ Kubernetes ကို ရောနှောထည့်သွင်းခြင်းသည် ကောင်းသော အကြံမဟုတ်နိုင်ပါ။ သင်၏ system တွင် microservice နှစ်ဆယ်ထက်ပိုပါက၊ သင်သည် Kubernetes ကို ပေါင်းစပ်ခြင်းမှ အကျိုးကျေးဇူး ရရှိနိုင်ဖွယ်ရှိပါသည်။

**သင်၏ engineer များ၏ အချိန်ကို Kubernetes လေ့လာရန်အတွက် ရင်းနှီးမြှုပ်နှံနိုင်ပါသလား။**

Kubernetes သည် application များက ၎င်းတို့ Kubernetes တွင် run နေသည်ကို မသိဘဲ run နိုင်စေရန် ဒီဇိုင်းထုတ်ထားပါသည်။ Application များကိုယ်တိုင်က Kubernetes တွင် run ရန် ပြင်ဆင်ရန် မလိုအပ်သော်လည်း၊ development engineer များသည် operator များသာ ထိုအသိပညာကို အမှန်တကယ် လိုအပ်သော်လည်း၊ Kubernetes ကို အသုံးပြုပုံကို လေ့လာရန် အချိန်များစွာ ကုန်ဆုံးကြမည်မှာ မလွဲဧကန်ဖြစ်သည်။

**ကြားကာလတွင် တိုးမြှင့်လာသော ကုန်ကျစရိတ်များအတွက် သင်အသင့်ဖြစ်ပြီလား။**

Kubernetes သည် ရေရှည် လည်ပတ်မှုကုန်ကျစရိတ်များကို လျှော့ချပေးသော်လည်း၊ သင်၏အဖွဲ့အစည်းတွင် Kubernetes ကို မိတ်ဆက်ခြင်းသည် အစပိုင်းတွင် လေ့ကျင့်ရေး၊ engineer အသစ်များ ငှားရမ်းခြင်း၊ tool အသစ်များ တည်ဆောက်ခြင်းနှင့် ဝယ်ယူခြင်းနှင့် ဖြစ်နိုင်ခြေရှိသော hardware အပိုများအတွက် ကုန်ကျစရိတ်များ တိုးမြှင့်ခြင်းတို့ ပါဝင်ပါသည်။

**Hype ကို မယုံပါနှင့်**

ဤစာအုပ်ကို ရေးသားနေချိန်တွင် Kubernetes သည် နှစ်ပေါင်းများစွာ ရှိနေပြီဖြစ်သော်လည်း၊ hype အဆင့် ပြီးဆုံးသွားပြီဟု ကျွန်တော်မပြောနိုင်ပါ။ ကနဦး စိတ်လှုပ်ရှားမှုသည် ငြိမ်သက်စပြုနေပြီဖြစ်သော်လည်း၊ engineer များစွာသည် Kubernetes ကို ပေါင်းစပ်ခြင်းသည် ထင်သလောက် လိုအပ်ခြင်း ရှိမရှိကို ဆင်ခြင်တုံတရားဖြင့် ဆုံးဖြတ်နိုင်ခြင်း မရှိသေးပေ။

## 1.4 အကျဉ်းချုပ်

ဤမိတ်ဆက်အခန်းတွင် သင်လေ့လာခဲ့သည်မှာ-

* Kubernetes သည် ဂရိဘာသာဖြင့် တက်မကိုင်ဟု အဓိပ္ပာယ်ရသည်။
* Kubernetes ကို 'ကူ-ဘာ-နက်-တီးစ်' ဟု အသံထွက်သည်။ kubectl ကို 'ကျူ့ဘ်-ကွန်ထရိုး' ဟု အသံထွက်သည်။
* Kubernetes သည် Google ၏ ကမ္ဘာလုံးဆိုင်ရာ အတိုင်းအတာဖြင့် application များ run ခဲ့သော ကြီးမားသည့် အတွေ့အကြုံပေါ်တွင် တည်ဆောက်ထားသော open-source project တစ်ခုဖြစ်သည်။
* Kubernetes သည် application deployment များကို ဖော်ပြရန် declarative model ကို အသုံးပြုသည်။
* Kubernetes သည် cluster အတွက် operating system တစ်ခုနှင့်တူသည်။ ၎င်းသည် infrastructure ကို abstract လုပ်ပြီး data center ရှိ ကွန်ပျူတာအားလုံးကို ကြီးမားသော၊ ဆက်စပ်နေသော deployment နေရာတစ်ခုအဖြစ် ဖော်ပြသည်။
* Microservice-based application များသည် monolithic application များထက် စီမံခန့်ခွဲရန် ပိုမိုခက်ခဲသည်။
* Kubernetes သည် development နှင့် operations အဖွဲ့များနှစ်ဖွဲ့လုံးကို ၎င်းတို့ အကောင်းဆုံးလုပ်ဆောင်နိုင်သည့်အရာကို လုပ်ဆောင်ရန် ကူညီပေးသည်။
* Kubernetes cluster တစ်ခုသည် master နှင့် worker node များဖြင့် ဖွဲ့စည်းထားသည်။ Master node များသည် cluster တစ်ခုလုံးကို ထိန်းချုပ်သည့် Control Plane ကို run ပြီး၊ worker node များသည် deploy လုပ်ထားသော application များ သို့မဟုတ် workload များကို run သောကြောင့် Workload Plane ကို ကိုယ်စားပြုသည်။
* Kubernetes ကို အသုံးပြုခြင်းသည် ရိုးရှင်းသော်လည်း ၎င်းကို စီမံခန့်ခွဲခြင်းသည် ခက်ခဲသည်။ အတွေ့အကြုံမရှိသော အဖွဲ့သည် Kubernetes ကို ကိုယ်တိုင် deploy လုပ်မည့်အစား Kubernetes-as-a-Service ဝန်ဆောင်မှုကို အသုံးပြုသင့်သည်။

ယခုအချိန်အထိ၊ သင်သည် သင်္ဘောကို ဆိပ်ခံတံတားမှသာ ကြည့်ရှုခဲ့သည်။ သင်္ဘောပေါ်သို့ တက်ရန် အချိန်ကျပြီဖြစ်သည်။ သို့သော် ဆိပ်ကမ်းမှ မထွက်ခွာမီ၊ ၎င်းသယ်ဆောင်လာသော shipping container များကို သင်စစ်ဆေးသင့်သည်။ နောက်အခန်းတွင် ထိုသို့လုပ်ဆောင်ပါမည်။
